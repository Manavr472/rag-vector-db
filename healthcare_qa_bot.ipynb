{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbafefdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully for Healthcare QA Bot with Self-Ask pattern!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Optional, Tuple, Union\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import re\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain.schema import Document\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "import logging\n",
    "from abc import ABC, abstractmethod\n",
    "import asyncio\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Libraries imported successfully for Healthcare QA Bot with Self-Ask pattern!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971cf2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¥ Healthcare Bot Configuration loaded\n",
      "ğŸ“ Vector dimension: 768\n",
      "âœ… Healthcare configuration ready!\n"
     ]
    }
   ],
   "source": [
    "# Healthcare Bot Configuration\n",
    "class HealthcareConfig:\n",
    "    def __init__(self):\n",
    "        # API Keys\n",
    "        self.gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "        self.pinecone_api_key = os.getenv('PINECONE_API_KEY')\n",
    "        \n",
    "        # Model configurations\n",
    "        self.embedding_model = \"models/embedding-001\"\n",
    "        self.chat_model = \"gemini-1.5-flash\"\n",
    "        self.max_tokens = 200\n",
    "        self.temperature = 0.2\n",
    "        \n",
    "        # Alternative: Use sentence-transformers for embeddings\n",
    "        self.use_sentence_transformers = False\n",
    "        self.sentence_transformer_model = \"all-MiniLM-L6-v2\"\n",
    "        \n",
    "        # Pinecone configurations\n",
    "        self.index_name = \"healthcare-qa-bot\"\n",
    "        \n",
    "        # Set dimensions based on embedding method\n",
    "        if self.use_sentence_transformers:\n",
    "            self.dimension = 384\n",
    "        else:\n",
    "            self.dimension = 768\n",
    "            \n",
    "        self.metric = \"cosine\"\n",
    "        \n",
    "        # Document processing\n",
    "        self.chunk_size = 800\n",
    "        self.chunk_overlap = 150\n",
    "        self.top_k_results = 7\n",
    "        \n",
    "        # Self-Ask specific settings\n",
    "        self.max_iterations = 3\n",
    "        self.confidence_threshold = 0.7\n",
    "        \n",
    "        # Validate API keys\n",
    "        if not self.gemini_api_key:\n",
    "            print(\"âš ï¸  Warning: GEMINI_API_KEY not found\")\n",
    "        if not self.pinecone_api_key:\n",
    "            print(\"âš ï¸  Warning: PINECONE_API_KEY not found\")\n",
    "        \n",
    "        # Configure Gemini API\n",
    "        if self.gemini_api_key:\n",
    "            genai.configure(api_key=self.gemini_api_key)\n",
    "        \n",
    "        print(f\"ğŸ¥ Healthcare Bot Configuration loaded\")\n",
    "        print(f\"ğŸ“ Vector dimension: {self.dimension}\")\n",
    "\n",
    "config = HealthcareConfig()\n",
    "print(\"âœ… Healthcare configuration ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf9c07de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Loading healthcare datasets from Hugging Face...\n",
      "Loading medical Q&A dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574aab2ae02746d5a1421a0d00226a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecbf6426124b440a8774e40317017301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "medical_dialog.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Could not load medical_dialog dataset: The repository for medical_dialog contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/medical_dialog.\n",
      "Please pass the argument `trust_remote_code=True` to allow custom code to be run.\n",
      "âœ… Loaded 5 healthcare documents\n"
     ]
    }
   ],
   "source": [
    "# Healthcare Dataset Loader\n",
    "class HealthcareDatasetLoader:\n",
    "    def __init__(self):\n",
    "        self.datasets = []\n",
    "        \n",
    "    def load_healthcare_datasets(self):\n",
    "        \"\"\"Load healthcare datasets from Hugging Face\"\"\"\n",
    "        print(\"ğŸ“Š Loading healthcare datasets from Hugging Face...\")\n",
    "        \n",
    "        try:\n",
    "            # Load medical Q&A dataset\n",
    "            print(\"Loading medical Q&A dataset...\")\n",
    "            medical_qa = load_dataset(\"medical_dialog\", split=\"train[:10000]\")  # Load first 1000 for demo\n",
    "            \n",
    "            # Process medical Q&A data\n",
    "            for item in medical_qa:\n",
    "                if 'utterances' in item:\n",
    "                    for utterance in item['utterances']:\n",
    "                        if utterance.get('speaker') == 'doctor':\n",
    "                            content = f\"Medical Q&A: {utterance.get('utterance', '')}\"\n",
    "                            self.datasets.append({\n",
    "                                \"content\": content,\n",
    "                                \"source\": \"medical_dialog_hf\",\n",
    "                                \"type\": \"medical_qa\"\n",
    "                            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Note: Could not load medical_dialog dataset: {e}\")\n",
    "        \n",
    "        # Add general healthcare knowledge base\n",
    "        healthcare_knowledge = [\n",
    "            {\n",
    "                \"content\": \"\"\"\n",
    "                Common Symptoms and Conditions:\n",
    "                \n",
    "                Fever: Body temperature above 100.4Â°F (38Â°C). Common causes include infections, \n",
    "                inflammatory conditions, and certain medications. Seek medical attention if fever \n",
    "                persists over 3 days or exceeds 103Â°F.\n",
    "                \n",
    "                Headaches: Can be tension-type, migraine, or cluster headaches. Tension headaches \n",
    "                are most common. Seek immediate care for sudden severe headache, headache with \n",
    "                neck stiffness, or headache after head injury.\n",
    "                \n",
    "                Chest Pain: Can range from minor muscle strain to serious heart conditions. \n",
    "                Seek immediate medical attention for crushing chest pain, pain radiating to arm/jaw, \n",
    "                or chest pain with shortness of breath.\n",
    "                \"\"\",\n",
    "                \"source\": \"general_healthcare_kb\",\n",
    "                \"type\": \"symptoms\"\n",
    "            },\n",
    "            {\n",
    "                \"content\": \"\"\"\n",
    "                Preventive Healthcare Guidelines:\n",
    "                \n",
    "                Regular Check-ups: Annual physical exams for adults, more frequent for chronic conditions.\n",
    "                Recommended screenings include blood pressure, cholesterol, diabetes, and cancer screenings.\n",
    "                \n",
    "                Vaccinations: Stay up-to-date with vaccines including flu, COVID-19, and others as \n",
    "                recommended by your healthcare provider.\n",
    "                \n",
    "                Healthy Lifestyle: Balanced diet, regular exercise (150 minutes moderate activity per week), \n",
    "                adequate sleep (7-9 hours), stress management, and avoiding tobacco and excessive alcohol.\n",
    "                \n",
    "                Mental Health: Regular mental health check-ins, stress management techniques, \n",
    "                and seeking help when needed.\n",
    "                \"\"\",\n",
    "                \"source\": \"preventive_care_kb\",\n",
    "                \"type\": \"prevention\"\n",
    "            },\n",
    "            {\n",
    "                \"content\": \"\"\"\n",
    "                Emergency Situations - When to Seek Immediate Care:\n",
    "                \n",
    "                Call 911 for: Chest pain, difficulty breathing, severe bleeding, loss of consciousness, \n",
    "                severe burns, suspected stroke (FAST: Face drooping, Arm weakness, Speech difficulty, Time).\n",
    "                \n",
    "                Go to ER for: High fever with severe symptoms, severe abdominal pain, severe headache \n",
    "                with vision changes, signs of severe allergic reaction.\n",
    "                \n",
    "                Urgent Care for: Minor cuts requiring stitches, sprains, minor burns, UTI symptoms, \n",
    "                minor infections.\n",
    "                \n",
    "                Primary Care for: Routine check-ups, medication management, chronic disease management, \n",
    "                preventive care.\n",
    "                \"\"\",\n",
    "                \"source\": \"emergency_care_kb\",\n",
    "                \"type\": \"emergency\"\n",
    "            },\n",
    "            {\n",
    "                \"content\": \"\"\"\n",
    "                Medication Safety and Management:\n",
    "                \n",
    "                Taking Medications: Follow prescribed dosages, take at recommended times, \n",
    "                complete full course of antibiotics, store properly.\n",
    "                \n",
    "                Drug Interactions: Inform healthcare providers of all medications including \n",
    "                over-the-counter drugs and supplements. Use one pharmacy when possible.\n",
    "                \n",
    "                Side Effects: Know common side effects, report unusual symptoms, never stop \n",
    "                medications suddenly without consulting healthcare provider.\n",
    "                \n",
    "                Generic vs Brand: Generic medications contain same active ingredients as brand names \n",
    "                and are equally effective but typically less expensive.\n",
    "                \"\"\",\n",
    "                \"source\": \"medication_safety_kb\",\n",
    "                \"type\": \"medications\"\n",
    "            },\n",
    "            {\n",
    "                \"content\": \"\"\"\n",
    "                Mental Health and Wellness:\n",
    "                \n",
    "                Signs of Depression: Persistent sadness, loss of interest, changes in appetite/sleep, \n",
    "                fatigue, difficulty concentrating, feelings of worthlessness.\n",
    "                \n",
    "                Anxiety Management: Deep breathing exercises, regular exercise, adequate sleep, \n",
    "                limiting caffeine, talking to trusted friends/family.\n",
    "                \n",
    "                Stress Reduction: Time management, relaxation techniques, hobbies, social support, \n",
    "                professional counseling when needed.\n",
    "                \n",
    "                When to Seek Help: Persistent symptoms affecting daily life, thoughts of self-harm, \n",
    "                substance abuse, relationship problems.\n",
    "                \"\"\",\n",
    "                \"source\": \"mental_health_kb\",\n",
    "                \"type\": \"mental_health\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Add healthcare knowledge to datasets\n",
    "        self.datasets.extend(healthcare_knowledge)\n",
    "        \n",
    "        print(f\"âœ… Loaded {len(self.datasets)} healthcare documents\")\n",
    "        return self.datasets\n",
    "\n",
    "# Initialize dataset loader\n",
    "dataset_loader = HealthcareDatasetLoader()\n",
    "healthcare_data = dataset_loader.load_healthcare_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c14f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¥ Creating healthcare index: healthcare-qa-bot\n",
      "âœ… Connected to healthcare Pinecone index\n",
      "Index stats: {'dimension': 768,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "# Healthcare Pinecone Manager\n",
    "class HealthcarePineconeManager:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.pc = None\n",
    "        self.index = None\n",
    "        \n",
    "    def initialize_pinecone(self):\n",
    "        \"\"\"Initialize Pinecone for healthcare data\"\"\"\n",
    "        try:\n",
    "            self.pc = Pinecone(api_key=self.config.pinecone_api_key)\n",
    "            \n",
    "            existing_indexes = [index.name for index in self.pc.list_indexes()]\n",
    "            \n",
    "            if self.config.index_name not in existing_indexes:\n",
    "                print(f\"ğŸ¥ Creating healthcare index: {self.config.index_name}\")\n",
    "                self.pc.create_index(\n",
    "                    name=self.config.index_name,\n",
    "                    dimension=self.config.dimension,\n",
    "                    metric=self.config.metric,\n",
    "                    spec=ServerlessSpec(\n",
    "                        cloud=\"aws\",\n",
    "                        region=\"us-east-1\"\n",
    "                    )\n",
    "                )\n",
    "                time.sleep(10)\n",
    "            else:\n",
    "                print(f\"Healthcare index {self.config.index_name} already exists\")\n",
    "            \n",
    "            self.index = self.pc.Index(self.config.index_name)\n",
    "            print(f\"âœ… Connected to healthcare Pinecone index\")\n",
    "            \n",
    "            stats = self.index.describe_index_stats()\n",
    "            print(f\"Index stats: {stats}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error initializing Pinecone: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# Initialize healthcare Pinecone manager\n",
    "pinecone_manager = HealthcarePineconeManager(config)\n",
    "\n",
    "if config.pinecone_api_key:\n",
    "    pinecone_manager.initialize_pinecone()\n",
    "else:\n",
    "    print(\"âš ï¸  Skipping Pinecone initialization - API key not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dad58a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¥ Healthcare document processing ready!\n"
     ]
    }
   ],
   "source": [
    "# Healthcare Document Processor\n",
    "class HealthcareDocumentProcessor:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=config.chunk_size,\n",
    "            chunk_overlap=config.chunk_overlap,\n",
    "            length_function=len,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    "        )\n",
    "        \n",
    "    def process_healthcare_data(self, healthcare_data: List[Dict]) -> List[Document]:\n",
    "        \"\"\"Process healthcare data into chunks\"\"\"\n",
    "        documents = []\n",
    "        \n",
    "        for item in healthcare_data:\n",
    "            content = item.get('content', '')\n",
    "            source = item.get('source', 'unknown')\n",
    "            doc_type = item.get('type', 'general')\n",
    "            \n",
    "            if content.strip():\n",
    "                chunks = self.text_splitter.split_text(content)\n",
    "                \n",
    "                for i, chunk in enumerate(chunks):\n",
    "                    doc = Document(\n",
    "                        page_content=chunk,\n",
    "                        metadata={\n",
    "                            \"source\": source,\n",
    "                            \"type\": doc_type,\n",
    "                            \"chunk_id\": i,\n",
    "                            \"total_chunks\": len(chunks)\n",
    "                        }\n",
    "                    )\n",
    "                    documents.append(doc)\n",
    "        \n",
    "        return documents\n",
    "\n",
    "# Healthcare Embedding Manager\n",
    "class HealthcareEmbeddingManager:\n",
    "    def __init__(self, config, pinecone_manager):\n",
    "        self.config = config\n",
    "        self.pinecone_manager = pinecone_manager\n",
    "        \n",
    "        if config.use_sentence_transformers:\n",
    "            self.embedding_model = SentenceTransformer(config.sentence_transformer_model)\n",
    "        else:\n",
    "            self.embedding_model = GoogleGenerativeAIEmbeddings(\n",
    "                model=config.embedding_model,\n",
    "                google_api_key=config.gemini_api_key\n",
    "            )\n",
    "    \n",
    "    def generate_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Generate embeddings for healthcare texts\"\"\"\n",
    "        if self.config.use_sentence_transformers:\n",
    "            return self.embedding_model.encode(texts).tolist()\n",
    "        else:\n",
    "            return self.embedding_model.embed_documents(texts)\n",
    "    \n",
    "    def store_healthcare_documents(self, documents: List[Document]):\n",
    "        \"\"\"Store healthcare documents in Pinecone\"\"\"\n",
    "        print(\"ğŸ¥ Storing healthcare documents...\")\n",
    "        \n",
    "        texts = [doc.page_content for doc in documents]\n",
    "        embeddings = self.generate_embeddings(texts)\n",
    "        \n",
    "        vectors = []\n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            vector_id = f\"healthcare_doc_{i}\"\n",
    "            metadata = {\n",
    "                \"text\": doc.page_content,\n",
    "                \"source\": doc.metadata.get(\"source\", \"unknown\"),\n",
    "                \"type\": doc.metadata.get(\"type\", \"general\")\n",
    "            }\n",
    "            vectors.append((vector_id, embedding, metadata))\n",
    "        \n",
    "        # Store in batches\n",
    "        batch_size = 100\n",
    "        for i in range(0, len(vectors), batch_size):\n",
    "            batch = vectors[i:i + batch_size]\n",
    "            self.pinecone_manager.index.upsert(vectors=batch)\n",
    "        \n",
    "        print(f\"âœ… Stored {len(vectors)} healthcare document vectors\")\n",
    "    \n",
    "    def search_healthcare_knowledge(self, query: str, top_k: int = None) -> List[Dict]:\n",
    "        \"\"\"Search healthcare knowledge base\"\"\"\n",
    "        if top_k is None:\n",
    "            top_k = self.config.top_k_results\n",
    "        \n",
    "        query_embedding = self.generate_embeddings([query])[0]\n",
    "        \n",
    "        results = self.pinecone_manager.index.query(\n",
    "            vector=query_embedding,\n",
    "            top_k=top_k,\n",
    "            include_metadata=True\n",
    "        )\n",
    "        \n",
    "        documents = []\n",
    "        for match in results['matches']:\n",
    "            documents.append({\n",
    "                'text': match['metadata']['text'],\n",
    "                'source': match['metadata']['source'],\n",
    "                'type': match['metadata']['type'],\n",
    "                'score': match['score']\n",
    "            })\n",
    "        \n",
    "        return documents\n",
    "\n",
    "# Initialize healthcare processors\n",
    "doc_processor = HealthcareDocumentProcessor(config)\n",
    "embedding_manager = HealthcareEmbeddingManager(config, pinecone_manager)\n",
    "\n",
    "print(\"ğŸ¥ Healthcare document processing ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b29be4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¥ Processing healthcare documents...\n",
      "ğŸ“„ Created 9 healthcare document chunks\n",
      "ğŸ“Š Index is empty, storing healthcare documents...\n",
      "ğŸ¥ Storing healthcare documents...\n",
      "âœ… Stored 9 healthcare document vectors\n",
      "âœ… Healthcare knowledge base ready!\n"
     ]
    }
   ],
   "source": [
    "# Process and Store Healthcare Data\n",
    "if config.pinecone_api_key and (config.gemini_api_key or config.use_sentence_transformers):\n",
    "    print(\"ğŸ¥ Processing healthcare documents...\")\n",
    "    \n",
    "    # Process healthcare data into documents\n",
    "    healthcare_documents = doc_processor.process_healthcare_data(healthcare_data)\n",
    "    print(f\"ğŸ“„ Created {len(healthcare_documents)} healthcare document chunks\")\n",
    "    \n",
    "    # Check if index is empty and store documents\n",
    "    stats = pinecone_manager.index.describe_index_stats()\n",
    "    \n",
    "    if stats['total_vector_count'] == 0:\n",
    "        print(\"ğŸ“Š Index is empty, storing healthcare documents...\")\n",
    "        embedding_manager.store_healthcare_documents(healthcare_documents)\n",
    "    else:\n",
    "        print(f\"ğŸ“Š Index already contains {stats['total_vector_count']} vectors\")\n",
    "    \n",
    "    print(\"âœ… Healthcare knowledge base ready!\")\n",
    "else:\n",
    "    print(\"âš ï¸  Skipping document storage - API keys not configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c42dedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¬ Greeting handler ready!\n"
     ]
    }
   ],
   "source": [
    "class GreetingHandler:\n",
    "    def __init__(self):\n",
    "        # Use Gemini LLM for intent detection and response\n",
    "        self.llm = None\n",
    "        if config.gemini_api_key:\n",
    "            self.llm = ChatGoogleGenerativeAI(\n",
    "                model=config.chat_model,\n",
    "                google_api_key=config.gemini_api_key,\n",
    "                temperature=config.temperature,\n",
    "                max_tokens=config.max_tokens\n",
    "            )\n",
    "\n",
    "    def detect_intent(self, text: str) -> str:\n",
    "        \"\"\"Use Gemini to classify the intent of the input text.\"\"\"\n",
    "        if not self.llm:\n",
    "            return \"unknown\"\n",
    "        prompt = f\"\"\"\n",
    "        Classify the following user message into one of these categories: greeting, farewell, thank_you, general_health_question, or other.\n",
    "        Message: \"{text}\"\n",
    "        Respond with only the category name.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.llm.invoke(prompt)\n",
    "            intent = response.content.strip().lower()\n",
    "            return intent\n",
    "        except Exception as e:\n",
    "            print(f\"Intent detection failed: {e}\")\n",
    "            return \"unknown\"\n",
    "\n",
    "    def generate_greeting_response(self, text: str) -> str:\n",
    "        \"\"\"Generate an appropriate conversational response using Gemini.\"\"\"\n",
    "        if not self.llm:\n",
    "            return None\n",
    "        intent = self.detect_intent(text)\n",
    "        prompt = f\"\"\"\n",
    "        You are a helpful healthcare assistant. Respond to the following user message appropriately, considering its intent: {intent}.\n",
    "        Message: \"{text}\"\n",
    "        If it's a greeting, introduce yourself as a healthcare assistant.\n",
    "        If it's a farewell, wish the user well and remind them to consult professionals for health concerns.\n",
    "        If it's a thank you, acknowledge and remind about educational purpose.\n",
    "        If it's a general health question about you, clarify you are an AI and offer help.\n",
    "        Otherwise, return \"None\".\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.llm.invoke(prompt)\n",
    "            reply = response.content.strip()\n",
    "            if reply.lower() == \"none\":\n",
    "                return None\n",
    "            return reply\n",
    "        except Exception as e:\n",
    "            print(f\"Greeting response failed: {e}\")\n",
    "            return None\n",
    "\n",
    "    def is_conversational(self, text: str) -> bool:\n",
    "        \"\"\"Use Gemini to determine if the text is conversational.\"\"\"\n",
    "        intent = self.detect_intent(text)\n",
    "        return intent in [\"greeting\", \"farewell\", \"thank_you\", \"general_health_question\"]\n",
    "\n",
    "# Initialize greeting handler\n",
    "greeting_handler = GreetingHandler()\n",
    "print(\"ğŸ’¬ Greeting handler (Gemini-powered) ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e6da186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  Self-Ask with Search system ready!\n"
     ]
    }
   ],
   "source": [
    "# Self-Ask with Search Implementation\n",
    "class SelfAskSearchSystem:\n",
    "    def __init__(self, config, embedding_manager):\n",
    "        self.config = config\n",
    "        self.embedding_manager = embedding_manager\n",
    "        \n",
    "        if config.gemini_api_key:\n",
    "            self.llm = ChatGoogleGenerativeAI(\n",
    "                model=config.chat_model,\n",
    "                google_api_key=config.gemini_api_key,\n",
    "                temperature=config.temperature,\n",
    "                max_tokens=config.max_tokens\n",
    "            )\n",
    "        else:\n",
    "            self.llm = None\n",
    "    \n",
    "    def decompose_question(self, question: str) -> List[str]:\n",
    "        \"\"\"Decompose complex question into sub-questions\"\"\"\n",
    "        if not self.llm:\n",
    "            return [question]\n",
    "        \n",
    "        decomposition_prompt = f\"\"\"\n",
    "        You are a healthcare assistant. Analyze this health question and break it down into simpler sub-questions if needed.\n",
    "        \n",
    "        Original question: {question}\n",
    "        \n",
    "        If this is a simple question, respond with just: [\"{question}\"]\n",
    "        If this is complex, break it into 2-3 simpler sub-questions as a JSON list.\n",
    "        \n",
    "        Examples:\n",
    "        - \"What is diabetes?\" â†’ [\"{question}\"]\n",
    "        - \"What are the symptoms and treatment options for diabetes?\" â†’ [\"What are the symptoms of diabetes?\", \"What are the treatment options for diabetes?\"]\n",
    "        \n",
    "        Respond only with a JSON list of sub-questions:\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.llm.invoke(decomposition_prompt)\n",
    "            response_text = response.content if hasattr(response, 'content') else str(response)\n",
    "            \n",
    "            # Extract JSON from response\n",
    "            import json\n",
    "            # Try to find JSON array in response\n",
    "            start = response_text.find('[')\n",
    "            end = response_text.rfind(']') + 1\n",
    "            if start != -1 and end != 0:\n",
    "                json_str = response_text[start:end]\n",
    "                sub_questions = json.loads(json_str)\n",
    "                return sub_questions\n",
    "            else:\n",
    "                return [question]\n",
    "        except Exception as e:\n",
    "            print(f\"Question decomposition failed: {e}\")\n",
    "            return [question]\n",
    "    \n",
    "    def search_and_answer(self, question: str) -> Dict[str, Any]:\n",
    "        \"\"\"Search for information and provide answer using Self-Ask pattern\"\"\"\n",
    "        print(f\"ğŸ” Self-Ask: {question}\")\n",
    "        \n",
    "        # Search for relevant information\n",
    "        search_results = self.embedding_manager.search_healthcare_knowledge(question)\n",
    "        \n",
    "        if not search_results:\n",
    "            return {\n",
    "                \"question\": question,\n",
    "                \"answer\": \"I don't have specific information about this topic in my healthcare knowledge base.\",\n",
    "                \"confidence\": 0.0,\n",
    "                \"sources\": []\n",
    "            }\n",
    "        \n",
    "        # Prepare context from search results\n",
    "        context_parts = []\n",
    "        sources = []\n",
    "        \n",
    "        for result in search_results[:5]:  # Top 5 results\n",
    "            context_parts.append(f\"Source ({result['type']}): {result['text']}\")\n",
    "            sources.append(f\"{result['source']} (relevance: {result['score']:.3f})\")\n",
    "        \n",
    "        context = \"\\n\\n\".join(context_parts)\n",
    "        \n",
    "        # Generate answer using LLM\n",
    "        if not self.llm:\n",
    "            return {\n",
    "                \"question\": question,\n",
    "                \"answer\": \"LLM not configured\",\n",
    "                \"confidence\": 0.0,\n",
    "                \"sources\": sources\n",
    "            }\n",
    "        \n",
    "        answer_prompt = f\"\"\"\n",
    "        You are a knowledgeable healthcare assistant. Answer the following health question using the provided medical context.\n",
    "        \n",
    "        IMPORTANT GUIDELINES:\n",
    "        - Provide accurate, helpful information based on the context\n",
    "        - Always include a disclaimer that this is for educational purposes\n",
    "        - Recommend consulting healthcare professionals for medical advice\n",
    "        - If the context doesn't contain relevant information, say so\n",
    "        - Be empathetic and professional\n",
    "        \n",
    "        Question: {question}\n",
    "        \n",
    "        Medical Context:\n",
    "        {context}\n",
    "        \n",
    "        Please provide a clear, helpful answer:\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.llm.invoke(answer_prompt)\n",
    "            answer = response.content if hasattr(response, 'content') else str(response)\n",
    "            \n",
    "            # Calculate confidence based on search results\n",
    "            avg_score = sum(result['score'] for result in search_results[:3]) / min(3, len(search_results))\n",
    "            confidence = min(avg_score, self.config.confidence_threshold)\n",
    "            \n",
    "            return {\n",
    "                \"question\": question,\n",
    "                \"answer\": answer,\n",
    "                \"confidence\": confidence,\n",
    "                \"sources\": sources\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"question\": question,\n",
    "                \"answer\": f\"Error generating answer: {str(e)}\",\n",
    "                \"confidence\": 0.0,\n",
    "                \"sources\": sources\n",
    "            }\n",
    "    \n",
    "    def self_ask_process(self, main_question: str) -> Dict[str, Any]:\n",
    "        \"\"\"Main Self-Ask process with iterative questioning\"\"\"\n",
    "        print(f\"ğŸ¤” Starting Self-Ask process for: {main_question}\")\n",
    "        \n",
    "        # Step 1: Decompose the question\n",
    "        sub_questions = self.decompose_question(main_question)\n",
    "        print(f\"ğŸ“ Sub-questions: {sub_questions}\")\n",
    "        \n",
    "        # Step 2: Answer each sub-question\n",
    "        sub_answers = []\n",
    "        all_sources = []\n",
    "        \n",
    "        for sub_q in sub_questions:\n",
    "            result = self.search_and_answer(sub_q)\n",
    "            sub_answers.append(result)\n",
    "            all_sources.extend(result['sources'])\n",
    "        \n",
    "        # Step 3: Synthesize final answer\n",
    "        if len(sub_answers) == 1:\n",
    "            final_result = sub_answers[0]\n",
    "        else:\n",
    "            # Combine answers for complex questions\n",
    "            combined_context = \"\\n\\n\".join([\n",
    "                f\"Q: {result['question']}\\nA: {result['answer']}\" \n",
    "                for result in sub_answers\n",
    "            ])\n",
    "            \n",
    "            synthesis_prompt = f\"\"\"\n",
    "            You are a healthcare assistant. I've broken down a complex health question into parts and got answers. \n",
    "            Please synthesize these into one comprehensive, coherent answer.\n",
    "            \n",
    "            Original question: {main_question}\n",
    "            \n",
    "            Sub-question answers:\n",
    "            {combined_context}\n",
    "            \n",
    "            Please provide a comprehensive answer that addresses the original question:\n",
    "            \"\"\"\n",
    "            \n",
    "            if self.llm:\n",
    "                try:\n",
    "                    response = self.llm.invoke(synthesis_prompt)\n",
    "                    final_answer = response.content if hasattr(response, 'content') else str(response)\n",
    "                    \n",
    "                    avg_confidence = sum(result['confidence'] for result in sub_answers) / len(sub_answers)\n",
    "                    \n",
    "                    final_result = {\n",
    "                        \"question\": main_question,\n",
    "                        \"answer\": final_answer,\n",
    "                        \"confidence\": avg_confidence,\n",
    "                        \"sources\": list(set(all_sources)),  # Remove duplicates\n",
    "                        \"sub_questions\": sub_questions,\n",
    "                        \"sub_answers\": sub_answers\n",
    "                    }\n",
    "                except Exception as e:\n",
    "                    final_result = {\n",
    "                        \"question\": main_question,\n",
    "                        \"answer\": f\"Error synthesizing answer: {str(e)}\",\n",
    "                        \"confidence\": 0.0,\n",
    "                        \"sources\": all_sources\n",
    "                    }\n",
    "            else:\n",
    "                final_result = {\n",
    "                    \"question\": main_question,\n",
    "                    \"answer\": \"LLM not configured for synthesis\",\n",
    "                    \"confidence\": 0.0,\n",
    "                    \"sources\": all_sources\n",
    "                }\n",
    "        \n",
    "        return final_result\n",
    "\n",
    "# Initialize Self-Ask system\n",
    "self_ask_system = SelfAskSearchSystem(config, embedding_manager)\n",
    "print(\"ğŸ§  Self-Ask with Search system ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dedceb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¥ Healthcare QA Bot with Self-Ask pattern ready!\n"
     ]
    }
   ],
   "source": [
    "# Main Healthcare QA Bot\n",
    "class HealthcareQABot:\n",
    "    def __init__(self, config, embedding_manager, self_ask_system, greeting_handler):\n",
    "        self.config = config\n",
    "        self.embedding_manager = embedding_manager\n",
    "        self.self_ask_system = self_ask_system\n",
    "        self.greeting_handler = greeting_handler\n",
    "        self.conversation_history = []\n",
    "        \n",
    "    def ask(self, question: str, verbose: bool = False) -> Dict[str, Any]:\n",
    "        \"\"\"Main method to ask healthcare questions\"\"\"\n",
    "        question = question.strip()\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"ğŸ¥ Healthcare Bot received: {question}\")\n",
    "        \n",
    "        # Check if it's a greeting or conversational\n",
    "        if self.greeting_handler.is_conversational(question):\n",
    "            greeting_response = self.greeting_handler.generate_greeting_response(question)\n",
    "            result = {\n",
    "                \"query\": question,\n",
    "                \"response\": greeting_response,\n",
    "                \"type\": \"conversational\",\n",
    "                \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "        else:\n",
    "            # Use Self-Ask with Search for medical questions\n",
    "            if verbose:\n",
    "                print(\"ğŸ” Processing as medical question with Self-Ask...\")\n",
    "            \n",
    "            self_ask_result = self.self_ask_system.self_ask_process(question)\n",
    "            \n",
    "            # Add medical disclaimer\n",
    "            medical_disclaimer = \"\\n\\nâš ï¸ **Medical Disclaimer**: This information is for educational purposes only and should not replace professional medical advice. Please consult with a healthcare provider for medical concerns.\"\n",
    "            \n",
    "            result = {\n",
    "                \"query\": question,\n",
    "                \"response\": self_ask_result[\"answer\"] + medical_disclaimer,\n",
    "                \"type\": \"medical\",\n",
    "                \"confidence\": self_ask_result[\"confidence\"],\n",
    "                \"sources\": self_ask_result[\"sources\"],\n",
    "                \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "            \n",
    "            if \"sub_questions\" in self_ask_result:\n",
    "                result[\"sub_questions\"] = self_ask_result[\"sub_questions\"]\n",
    "                result[\"sub_answers\"] = self_ask_result[\"sub_answers\"]\n",
    "        \n",
    "        # Add to conversation history\n",
    "        self.conversation_history.append(result)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"ğŸ’¬ Response: {result['response']}\")\n",
    "            if result.get('sources'):\n",
    "                print(f\"ğŸ“š Sources: {len(result['sources'])} references\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_conversation_history(self) -> List[Dict]:\n",
    "        \"\"\"Get conversation history\"\"\"\n",
    "        return self.conversation_history\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"Clear conversation history\"\"\"\n",
    "        self.conversation_history = []\n",
    "        print(\"ğŸ—‘ï¸ Conversation history cleared\")\n",
    "\n",
    "# Initialize Healthcare QA Bot\n",
    "healthcare_bot = HealthcareQABot(config, embedding_manager, self_ask_system, greeting_handler)\n",
    "print(\"ğŸ¥ Healthcare QA Bot with Self-Ask pattern ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7a53068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Healthcare QA Bot\n",
    "def test_healthcare_bot():\n",
    "    \"\"\"Test the healthcare bot with various types of questions\"\"\"\n",
    "    \n",
    "    if not ((config.gemini_api_key or config.use_sentence_transformers) and config.pinecone_api_key):\n",
    "        print(\"âš ï¸  Cannot test - API keys not configured\")\n",
    "        return\n",
    "    \n",
    "    print(\"ğŸ§ª Testing Healthcare QA Bot with Self-Ask pattern...\\n\")\n",
    "    \n",
    "    # Test questions covering different scenarios\n",
    "    test_questions = [\n",
    "        # Greetings\n",
    "        \"Hello!\",\n",
    "        \"Hi there, how are you?\",\n",
    "        \n",
    "        # Simple medical questions\n",
    "        \"What is diabetes?\",\n",
    "        \"What are the symptoms of fever?\",\n",
    "        \n",
    "        # Complex medical questions (will trigger Self-Ask decomposition)\n",
    "        \"What are the symptoms and treatment options for high blood pressure?\",\n",
    "        \"How can I prevent heart disease and what are the warning signs?\",\n",
    "        \n",
    "        # Emergency situations\n",
    "        \"When should I go to the emergency room?\",\n",
    "        \n",
    "        # Medication questions\n",
    "        \"How should I store my medications?\",\n",
    "        \n",
    "        # Mental health\n",
    "        \"What are signs of depression?\",\n",
    "        \n",
    "        # Thank you\n",
    "        \"Thank you for your help!\",\n",
    "        \"Goodbye\"\n",
    "    ]\n",
    "    \n",
    "    for i, question in enumerate(test_questions, 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Test {i}: {question}\")\n",
    "        print('='*60)\n",
    "        \n",
    "        try:\n",
    "            result = healthcare_bot.ask(question, verbose=True)\n",
    "            \n",
    "            if result.get('sources'):\n",
    "                print(f\"\\nğŸ“š Sources used:\")\n",
    "                for source in result['sources'][:3]:  # Show top 3 sources\n",
    "                    print(f\"  - {source}\")\n",
    "            \n",
    "            if result.get('sub_questions'):\n",
    "                print(f\"\\nğŸ¤” Sub-questions identified:\")\n",
    "                for sub_q in result['sub_questions']:\n",
    "                    print(f\"  - {sub_q}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error testing question: {str(e)}\")\n",
    "        \n",
    "        time.sleep(1)  # Small delay between requests\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ğŸ‰ Healthcare bot testing completed!\")\n",
    "    print(f\"ğŸ’¬ Total conversations: {len(healthcare_bot.get_conversation_history())}\")\n",
    "\n",
    "# Run the test (uncomment to test)\n",
    "# test_healthcare_bot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a56cb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¡ To test the healthcare bot:\n",
      "   test_healthcare_bot()      # For automated testing\n",
      "   interactive_healthcare_chat()  # For interactive mode\n",
      "\n",
      "ğŸ”§ Configuration status:\n",
      "   - Gemini API: âœ…\n",
      "   - Sentence Transformers: âŒ\n",
      "   - Pinecone: âœ…\n",
      "   - Healthcare Data: âœ… 5 documents loaded\n"
     ]
    }
   ],
   "source": [
    "# Interactive Healthcare Chat\n",
    "def interactive_healthcare_chat():\n",
    "    \"\"\"Interactive chat interface for healthcare bot\"\"\"\n",
    "    \n",
    "    if not ((config.gemini_api_key or config.use_sentence_transformers) and config.pinecone_api_key):\n",
    "        print(\"âš ï¸  Cannot start interactive mode - API keys not configured\")\n",
    "        print(\"ğŸ’¡ Please set GEMINI_API_KEY and PINECONE_API_KEY in your .env file\")\n",
    "        return\n",
    "    \n",
    "    print(\"ğŸ¥ Welcome to Healthcare Assistant! (Powered by Self-Ask with Search)\")\n",
    "    print(\"ğŸ’¬ Ask me about health topics, symptoms, treatments, or just say hello!\")\n",
    "    print(\"ğŸ” I use Self-Ask pattern to break down complex questions\")\n",
    "    print(\"âš ï¸  Remember: This is for educational purposes only. Consult healthcare professionals for medical advice.\")\n",
    "    print(\"Type 'quit' to exit.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # Get user input\n",
    "            question = input(\"ğŸ¤” Your question: \").strip()\n",
    "            \n",
    "            if question.lower() in ['quit', 'exit', 'bye', 'goodbye']:\n",
    "                final_response = healthcare_bot.ask(\"goodbye\")\n",
    "                print(f\"\\nğŸ¥ Healthcare Bot: {final_response['response']}\")\n",
    "                break\n",
    "            \n",
    "            if not question:\n",
    "                print(\"Please ask a question or type 'quit' to exit.\")\n",
    "                continue\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            \n",
    "            # Get answer from healthcare bot\n",
    "            result = healthcare_bot.ask(question, verbose=False)\n",
    "            \n",
    "            print(f\"ğŸ¥ Healthcare Bot: {result['response']}\")\n",
    "            \n",
    "            # Show additional info for medical questions\n",
    "            if result.get('type') == 'medical':\n",
    "                if result.get('confidence'):\n",
    "                    print(f\"\\nğŸ“Š Confidence: {result['confidence']:.2f}\")\n",
    "                \n",
    "                if result.get('sub_questions') and len(result['sub_questions']) > 1:\n",
    "                    print(f\"\\nğŸ¤” I broke your question into parts:\")\n",
    "                    for sub_q in result['sub_questions']:\n",
    "                        print(f\"  â€¢ {sub_q}\")\n",
    "                \n",
    "                if result.get('sources'):\n",
    "                    print(f\"\\nğŸ“š Information sources: {len(result['sources'])} references\")\n",
    "            \n",
    "            print(\"=\"*50 + \"\\n\")\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nğŸ‘‹ Stay healthy! Goodbye!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error: {str(e)}\")\n",
    "\n",
    "# Example usage\n",
    "print(\"ğŸ’¡ To test the healthcare bot:\")\n",
    "print(\"   test_healthcare_bot()      # For automated testing\")\n",
    "print(\"   interactive_healthcare_chat()  # For interactive mode\")\n",
    "print(\"\\nğŸ”§ Configuration status:\")\n",
    "print(f\"   - Gemini API: {'âœ…' if config.gemini_api_key else 'âŒ'}\")\n",
    "print(f\"   - Sentence Transformers: {'âœ…' if config.use_sentence_transformers else 'âŒ'}\")\n",
    "print(f\"   - Pinecone: {'âœ…' if config.pinecone_api_key else 'âŒ'}\")\n",
    "print(f\"   - Healthcare Data: âœ… {len(healthcare_data)} documents loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4563f7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¥ Welcome to Healthcare Assistant! (Powered by Self-Ask with Search)\n",
      "ğŸ’¬ Ask me about health topics, symptoms, treatments, or just say hello!\n",
      "ğŸ” I use Self-Ask pattern to break down complex questions\n",
      "âš ï¸  Remember: This is for educational purposes only. Consult healthcare professionals for medical advice.\n",
      "Type 'quit' to exit.\n",
      "\n",
      "\n",
      "==================================================\n",
      "ğŸ¤” Starting Self-Ask process for: what is fever\n",
      "ğŸ“ Sub-questions: ['What is the definition of fever?', 'What causes a fever?', 'What are the symptoms of a fever?']\n",
      "ğŸ” Self-Ask: What is the definition of fever?\n",
      "ğŸ” Self-Ask: What causes a fever?\n",
      "ğŸ” Self-Ask: What are the symptoms of a fever?\n",
      "ğŸ¥ Healthcare Bot: A fever is defined as a body temperature above 100.4Â°F (38Â°C).  While an elevated temperature is the defining characteristic, it's crucial to understand that a fever is usually a *symptom* of an underlying condition, not a disease itself.  Common causes include infections (viral, bacterial, or fungal), inflammatory conditions, and certain medications.  Other symptoms may accompany a fever, depending on the underlying cause.  These could range from mild discomfort to severe symptoms depending on the severity and cause of the fever.\n",
      "\n",
      "It's important to seek medical attention if your fever persists for more than three days or exceeds 103Â°F (39.4Â°C).  A high fever accompanied by severe symptoms (such as difficulty breathing, severe headache, stiff neck, or confusion) also warrants immediate medical evaluation.  This information is for educational purposes only and should not be considered medical advice.  Always consult a healthcare professional for any\n",
      "\n",
      "âš ï¸ **Medical Disclaimer**: This information is for educational purposes only and should not replace professional medical advice. Please consult with a healthcare provider for medical concerns.\n",
      "\n",
      "ğŸ“Š Confidence: 0.70\n",
      "\n",
      "ğŸ¤” I broke your question into parts:\n",
      "  â€¢ What is the definition of fever?\n",
      "  â€¢ What causes a fever?\n",
      "  â€¢ What are the symptoms of a fever?\n",
      "\n",
      "ğŸ“š Information sources: 15 references\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "ğŸ¥ Healthcare Bot: Hello! I'm your healthcare assistant. I'm here to help answer your health-related questions and provide general medical information. How can I assist you today?\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "ğŸ¤” Starting Self-Ask process for: i have temp over 40 C\n",
      "ğŸ“ Sub-questions: ['What is your current temperature in Celsius?', 'How long have you had a temperature over 40Â°C?', 'Are you experiencing any other symptoms (e.g., headache, chills, muscle aches)?']\n",
      "ğŸ” Self-Ask: What is your current temperature in Celsius?\n",
      "ğŸ” Self-Ask: How long have you had a temperature over 40Â°C?\n",
      "ğŸ” Self-Ask: Are you experiencing any other symptoms (e.g., headache, chills, muscle aches)?\n",
      "ğŸ¥ Healthcare Bot: You have reported a temperature over 40Â°C (104Â°F), which is a serious medical emergency.  This high fever requires immediate medical attention.  You should go to the nearest emergency room (ER) or call emergency services immediately.\n",
      "\n",
      "The duration of your fever is unknown, but a temperature this high, regardless of duration, necessitates urgent medical care.  While other symptoms such as headache, chills, and muscle aches are common with high fevers and could be present,  the priority is addressing the dangerously high temperature itself.  Any additional symptoms you are experiencing should be reported to the medical professionals at the ER.  Do not attempt to treat this at home.  Delaying treatment could have serious consequences.\n",
      "\n",
      "âš ï¸ **Medical Disclaimer**: This information is for educational purposes only and should not replace professional medical advice. Please consult with a healthcare provider for medical concerns.\n",
      "\n",
      "ğŸ“Š Confidence: 0.70\n",
      "\n",
      "ğŸ¤” I broke your question into parts:\n",
      "  â€¢ What is your current temperature in Celsius?\n",
      "  â€¢ How long have you had a temperature over 40Â°C?\n",
      "  â€¢ Are you experiencing any other symptoms (e.g., headache, chills, muscle aches)?\n",
      "\n",
      "ğŸ“š Information sources: 15 references\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "ğŸ¤” Starting Self-Ask process for: i feel numb in legs\n",
      "ğŸ“ Sub-questions: ['When did the numbness in your legs start?', 'Where exactly in your legs do you feel the numbness?', 'Do you experience any other symptoms along with the numbness, such as pain, tingling, weakness, or changes in bowel or bladder function?']\n",
      "ğŸ” Self-Ask: When did the numbness in your legs start?\n",
      "ğŸ” Self-Ask: Where exactly in your legs do you feel the numbness?\n",
      "ğŸ” Self-Ask: Do you experience any other symptoms along with the numbness, such as pain, tingling, weakness, or changes in bowel or bladder function?\n",
      "ğŸ¥ Healthcare Bot: I understand you're experiencing numbness in your legs.  Unfortunately, the information provided doesn't give me any details about the onset, location, or associated symptoms of your leg numbness.  Therefore, I cannot provide a specific answer regarding the cause of your numbness.\n",
      "\n",
      "**It is crucial that you seek medical attention immediately.** Leg numbness can be a symptom of various serious conditions.  A healthcare professional needs to assess your symptoms thoroughly, including when the numbness started, the exact location in your legs, and whether you experience any other symptoms such as pain, tingling, weakness, or changes in bowel or bladder function.  They can perform a proper examination and potentially order tests to determine the underlying cause and recommend appropriate treatment.\n",
      "\n",
      "**Do not delay seeking medical care.**  This information is for educational purposes only and is not a substitute for professional medical advice.\n",
      "\n",
      "âš ï¸ **Medical Disclaimer**: This information is for educational purposes only and should not replace professional medical advice. Please consult with a healthcare provider for medical concerns.\n",
      "\n",
      "ğŸ“Š Confidence: 0.70\n",
      "\n",
      "ğŸ¤” I broke your question into parts:\n",
      "  â€¢ When did the numbness in your legs start?\n",
      "  â€¢ Where exactly in your legs do you feel the numbness?\n",
      "  â€¢ Do you experience any other symptoms along with the numbness, such as pain, tingling, weakness, or changes in bowel or bladder function?\n",
      "\n",
      "ğŸ“š Information sources: 15 references\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "ğŸ¤” Starting Self-Ask process for: heavy heart too\n",
      "ğŸ“ Sub-questions: [\"Can you describe what you mean by 'heavy heart'?\", 'Are you experiencing any chest pain or discomfort?', 'Have you noticed any other symptoms, such as shortness of breath or dizziness?']\n",
      "ğŸ” Self-Ask: Can you describe what you mean by 'heavy heart'?\n",
      "ğŸ” Self-Ask: Are you experiencing any chest pain or discomfort?\n",
      "ğŸ” Self-Ask: Have you noticed any other symptoms, such as shortness of breath or dizziness?\n"
     ]
    }
   ],
   "source": [
    "interactive_healthcare_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26a7391d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¥ Healthcare QA Bot Demo with Self-Ask Pattern\n",
      "==================================================\n",
      "\n",
      "ğŸ‘¤ User: Hello!\n",
      "ğŸ¥ Bot: Hello! I'm your healthcare assistant. I'm here to help answer your health-related questions and provide general medical information. How can I assist you today?...\n",
      "\n",
      "ğŸ‘¤ User: What are the symptoms of diabetes?\n",
      "ğŸ¤” Starting Self-Ask process for: What are the symptoms of diabetes?\n",
      "ğŸ“ Sub-questions: ['What are the common symptoms of type 1 diabetes?', 'What are the common symptoms of type 2 diabetes?', 'What are some less common or subtle symptoms of diabetes?']\n",
      "ğŸ” Self-Ask: What are the common symptoms of type 1 diabetes?\n",
      "ğŸ” Self-Ask: What are the common symptoms of type 2 diabetes?\n",
      "ğŸ” Self-Ask: What are some less common or subtle symptoms of diabetes?\n",
      "ğŸ¥ Bot: I apologize, but I cannot provide a comprehensive answer to your question about the symptoms of diabetes.  My knowledge base currently lacks the necessary information on the symptoms of both type 1 an...\n",
      "ğŸ¤” Self-Ask decomposed into: ['What are the common symptoms of type 1 diabetes?', 'What are the common symptoms of type 2 diabetes?', 'What are some less common or subtle symptoms of diabetes?']\n",
      "\n",
      "ğŸ‘¤ User: What are the symptoms and treatment options for high blood pressure?\n",
      "ğŸ¥ Bot: Hello! I'm your healthcare assistant. I'm here to help answer your health-related questions and provide general medical information. How can I assist you today?...\n",
      "\n",
      "==================================================\n",
      "ğŸ¯ Healthcare Bot Features:\n",
      "âœ… Self-Ask with Search pattern for complex questions\n",
      "âœ… Healthcare dataset from Hugging Face + curated knowledge\n",
      "âœ… Greeting and conversational handling\n",
      "âœ… Medical disclaimers and safety recommendations\n",
      "âœ… Question decomposition for complex queries\n",
      "âœ… Confidence scoring and source attribution\n"
     ]
    }
   ],
   "source": [
    "# Quick Demo of Healthcare Bot\n",
    "print(\"ğŸ¥ Healthcare QA Bot Demo with Self-Ask Pattern\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Demo conversations\n",
    "demo_questions = [\n",
    "    \"Hello!\",\n",
    "    \"What are the symptoms of diabetes?\",\n",
    "    \"What are the symptoms and treatment options for high blood pressure?\"\n",
    "]\n",
    "\n",
    "for question in demo_questions:\n",
    "    print(f\"\\nğŸ‘¤ User: {question}\")\n",
    "    result = healthcare_bot.ask(question)\n",
    "    print(f\"ğŸ¥ Bot: {result['response'][:200]}...\")  # Truncate for demo\n",
    "    \n",
    "    if result.get('sub_questions') and len(result['sub_questions']) > 1:\n",
    "        print(f\"ğŸ¤” Self-Ask decomposed into: {result['sub_questions']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ğŸ¯ Healthcare Bot Features:\")\n",
    "print(\"âœ… Self-Ask with Search pattern for complex questions\")\n",
    "print(\"âœ… Healthcare dataset from Hugging Face + curated knowledge\")\n",
    "print(\"âœ… Greeting and conversational handling\")\n",
    "print(\"âœ… Medical disclaimers and safety recommendations\")\n",
    "print(\"âœ… Question decomposition for complex queries\")\n",
    "print(\"âœ… Confidence scoring and source attribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a255fdd7",
   "metadata": {},
   "source": [
    "# Healthcare QA Bot - Self-Ask with Search Implementation\n",
    "\n",
    "## Project Overview\n",
    "This notebook implements a healthcare question-answering system using the **Self-Ask with Search** pattern, integrating Google Gemini API, Pinecone vector database, and Hugging Face healthcare datasets.\n",
    "\n",
    "## Key Features\n",
    "- **Self-Ask Pattern**: Decomposes complex questions into simpler sub-questions for better understanding\n",
    "- **Healthcare Dataset Integration**: Uses Hugging Face medical datasets plus curated healthcare knowledge\n",
    "- **Conversational Handling**: Manages greetings, farewells, and general conversation\n",
    "- **Medical Safety**: Includes appropriate disclaimers and safety recommendations\n",
    "- **Search-Based Retrieval**: Vector similarity search with confidence scoring\n",
    "\n",
    "## Technical Architecture\n",
    "1. **Question Analysis**: Determines if input is conversational or medical\n",
    "2. **Question Decomposition**: Breaks complex queries into manageable sub-questions\n",
    "3. **Search Process**: Retrieves relevant medical information for each sub-question\n",
    "4. **Answer Synthesis**: Combines sub-answers into comprehensive response\n",
    "5. **Safety Layer**: Adds medical disclaimers and professional consultation recommendations\n",
    "\n",
    "## Self-Ask vs ReACT Comparison\n",
    "- **Self-Ask**: Focuses on question decomposition and iterative search\n",
    "- **ReACT**: Emphasizes reasoning, acting, and observing with tool usage\n",
    "- **Healthcare Context**: Self-Ask better suits medical Q&A where breaking down symptoms/treatments is crucial\n",
    "\n",
    "## Main Components\n",
    "- `HealthcareConfig`: System configuration for medical domain\n",
    "- `HealthcareDatasetLoader`: Loads Hugging Face medical datasets\n",
    "- `GreetingHandler`: Manages conversational interactions\n",
    "- `SelfAskSearchSystem`: Core Self-Ask implementation with search\n",
    "- `HealthcareQABot`: Main interface integrating all components\n",
    "\n",
    "## Data Sources\n",
    "- **Hugging Face**: Medical dialog datasets for real medical conversations\n",
    "- **Curated Knowledge**: Symptoms, treatments, emergency care, mental health\n",
    "- **Safety Guidelines**: Medication management, when to seek care\n",
    "\n",
    "## Usage Example\n",
    "```python\n",
    "# Initialize and use the healthcare bot\n",
    "healthcare_bot = HealthcareQABot(config, embedding_manager, self_ask_system, greeting_handler)\n",
    "\n",
    "# Ask a complex question\n",
    "result = healthcare_bot.ask(\"What are the symptoms and treatment options for diabetes?\")\n",
    "\n",
    "# The bot will:\n",
    "# 1. Decompose into: [\"What are symptoms of diabetes?\", \"What are treatment options for diabetes?\"]\n",
    "# 2. Search medical knowledge for each sub-question\n",
    "# 3. Synthesize comprehensive answer with medical disclaimer\n",
    "```\n",
    "\n",
    "## Performance Features\n",
    "- **Question Decomposition**: Automatically breaks complex medical queries\n",
    "- **Confidence Scoring**: Relevance-based confidence metrics\n",
    "- **Source Attribution**: Tracks information sources for transparency\n",
    "- **Conversation History**: Maintains context across interactions\n",
    "\n",
    "This implementation demonstrates advanced AI techniques specifically tailored for healthcare information systems with appropriate safety measures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d90f22",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
